{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEIEQWP1vAtx",
        "outputId": "7736e494-73db-47c0-ea92-40b1c21e34e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh3ksgf3yegt",
        "outputId": "ca6574c1-01bc-4908-f5b2-835245a145fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build sequential model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "metadata": {
        "id": "XUpJHXUJzFkM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#return a vector of logtis or log-odds scores for ea. classs\n",
        "predictions = model(x_train[:1]).numpy()\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neJKK8iAzXWK",
        "outputId": "dfaeca3a-38cd-4ec5-c29b-ada9a755e5af"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.640564  , -0.29221085, -0.60625386,  0.86658865,  0.44622576,\n",
              "         0.4431529 , -0.590907  , -0.42628005, -0.64759946, -0.27601987]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert logits to probabilities for ea. class\n",
        "tf.nn.softmax(predictions).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mwo47ApPCeG",
        "outputId": "16d9b137-8b76-4f7e-b0df-c224bc997afe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16976969, 0.06679764, 0.04879485, 0.21282439, 0.13978484,\n",
              "        0.13935597, 0.04954948, 0.05841652, 0.04681854, 0.06788797]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define loss function for training\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "#loss function takes vector of ground truth values and vector of logits and returns a scalar loss for each example.\n",
        "#basically it quantifies the difference between the predicted outputs of a model and the actual ground truth labels.\n",
        "#signals a model about the direction it needs to adjust it's parameters to improve.\n",
        "#different models require different loss functions.\n",
        "#ex, cross-entropy loss, hinge loss, softmax loss....\n"
      ],
      "metadata": {
        "id": "luRMlVv1PHi6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set optimizer class to adam, set loss to the loss_fn function to specify a metric to be evaluated for the model (do this by setting metrics param to accuracy)\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SZB_HP6SSZOD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train and evaluate the model\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xEVuPjyU8H3",
        "outputId": "35b4ef90-b623-4f31-bb40-893bffb7c37e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.2975 - accuracy: 0.9134\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1462 - accuracy: 0.9557\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1091 - accuracy: 0.9669\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0882 - accuracy: 0.9722\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0753 - accuracy: 0.9766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a830df59060>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.evaluate() check the model's performance\n",
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUPg8h7lU93W",
        "outputId": "b0b8eab5-88e2-41c4-ac7c-313b9039f7a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 1s - loss: 0.0842 - accuracy: 0.9753 - 740ms/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0841759741306305, 0.9753000140190125]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to return a probability, wrap trained model and attach softmax to it:\n",
        "probability_model = tf.keras.Sequential([\n",
        "    model,\n",
        "    tf.keras.layers.Softmax()\n",
        "])\n",
        "\n",
        "probability_model(x_test[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn4OW5z8VLvd",
        "outputId": "a44e5ba8-b080-4323-ac06-bb72f89dee8a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
              "array([[1.19585238e-07, 4.93405261e-10, 4.34807907e-06, 1.45552011e-04,\n",
              "        4.00014955e-13, 4.03348878e-07, 2.88218885e-13, 9.99848485e-01,\n",
              "        7.27793065e-07, 5.04393881e-07],\n",
              "       [7.86066551e-07, 1.49074799e-06, 9.99990940e-01, 6.43670046e-06,\n",
              "        1.72813171e-16, 1.97800844e-07, 9.60585851e-08, 8.48830605e-15,\n",
              "        3.78516418e-08, 4.03250872e-15],\n",
              "       [1.58395881e-06, 9.99075294e-01, 3.06599628e-04, 1.32638688e-05,\n",
              "        1.72162145e-05, 3.91160247e-05, 2.87698804e-05, 3.54463788e-04,\n",
              "        1.60743803e-04, 2.87601824e-06],\n",
              "       [9.99916077e-01, 9.44082104e-11, 6.77095959e-05, 1.48085535e-08,\n",
              "        1.00536619e-08, 1.17436193e-05, 7.65748666e-07, 1.07643939e-06,\n",
              "        6.01707173e-09, 2.59467561e-06],\n",
              "       [5.03445608e-06, 1.42071255e-09, 2.27457931e-05, 1.17281934e-06,\n",
              "        9.93002951e-01, 5.59478963e-07, 2.36182836e-06, 4.87113502e-05,\n",
              "        6.54582345e-06, 6.90993108e-03]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ps-iZJlhw7QR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}